**Assignment 1:**
This project is to find the top frequent words and analysing the performance metrics which varies based on the size of the input dataset without using big data tech.
Multithreading approach is used here
To execute the java/python file : Change the path of the inupt data set and run

**Assignment 2:**
This Assignment focuses on utilizing the MapReduce paradigm to efficiently process large datasets. The task is to identify the top 100 most frequently occurring words in
a given dataset, with a specific emphasis on words that consist of more than six characters.Comparing Assignment 1 to see how much of processing time is reduced using Hadoop Map Reduce
